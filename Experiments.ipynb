{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLNMGzN+SFeX6e5SQjMDhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ps-research/Novel-Enhanced-Quantum-Representation-for-Biological-Sequence-Comparison/blob/main/Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit==0.40 pylatexenc qiskit-aer --quiet"
      ],
      "metadata": {
        "id": "3NbSju25QMU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 1: IMPORTS AND SETUP\n",
        "# ============================================================================\n",
        "import warnings\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Ensure Qiskit is installed\n",
        "try:\n",
        "    from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, transpile\n",
        "    from qiskit_aer import AerSimulator\n",
        "    from qiskit.providers.aer.noise import NoiseModel, depolarizing_error\n",
        "    from qiskit.visualization import circuit_drawer\n",
        "except ImportError:\n",
        "    print(\"Installing Qiskit...\")\n",
        "    !pip install qiskit==0.40 pylatexenc qiskit-aer --quiet\n",
        "    from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, transpile\n",
        "    from qiskit_aer import AerSimulator\n",
        "    from qiskit.providers.aer.noise import NoiseModel, depolarizing_error\n",
        "    from qiskit.visualization import circuit_drawer\n",
        "    print(\"Qiskit installed successfully.\")"
      ],
      "metadata": {
        "id": "_H7ST9B8MJs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# --- HOUSE STYLE CONFIGURATION ---\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 1. Define the official color palette (from viridis)\n",
        "HOUSE_STYLE_COLORS = {\n",
        "    'NEQR': '#440154',  # Dark Purple/Indigo\n",
        "    'FRQI': '#fde725',  # Bright Yellow\n",
        "    'Classical Hamming': '#21908d' # Teal\n",
        "}\n",
        "VIRIDIS_PALETTE = 'viridis'\n",
        "\n",
        "# 2. Set consistent font sizes and plot aesthetics\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "plt.rcParams['savefig.facecolor'] = 'white'\n",
        "# Font Hierarchy\n",
        "plt.rcParams['figure.titlesize'] = 18\n",
        "plt.rcParams['axes.titlesize'] = 16\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "plt.rcParams['legend.fontsize'] = 12\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
        "\n",
        "# 3. Create a helper function to apply consistent styling to any plot\n",
        "def apply_house_style(ax, title=\"\"):\n",
        "    \"\"\"Applies consistent styling (grid, spines, title) to a Matplotlib axes object.\"\"\"\n",
        "    ax.grid(True, which='major', axis='y', linestyle='--', color='lightgray', zorder=0)\n",
        "    sns.despine(ax=ax, top=True, right=True)\n",
        "    ax.set_title(title, pad=15)\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# Setup directories\n",
        "os.makedirs('results', exist_ok=True)\n",
        "os.makedirs('results/figures', exist_ok=True)\n",
        "os.makedirs('results/tables', exist_ok=True)\n",
        "os.makedirs('results/checkpoints', exist_ok=True)\n",
        "\n",
        "print(\"Quantum DNA Sequence Comparison Analysis (Enhanced with GC Content Analysis)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Output directory: 'results/'\")"
      ],
      "metadata": {
        "id": "wx1IzPYeMQXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 2: CORE QUANTUM CIRCUIT IMPLEMENTATIONS (Unchanged)\n",
        "# ============================================================================\n",
        "\n",
        "class QuantumDNAEncoder:\n",
        "    \"\"\"Base class for quantum DNA encoding methods.\"\"\"\n",
        "    @staticmethod\n",
        "    def nucleotide_to_binary(nucleotide):\n",
        "        mapping = {'A': '00', 'T': '01', 'G': '10', 'C': '11'}\n",
        "        return mapping.get(nucleotide.upper(), '00')\n",
        "\n",
        "    @staticmethod\n",
        "    def nucleotide_to_angle(nucleotide):\n",
        "        mapping = {'A': np.pi, 'C': np.pi / 2, 'T': np.pi / 6, 'G': 0}\n",
        "        return mapping.get(nucleotide.upper(), 0)\n",
        "\n",
        "class NEQREncoder(QuantumDNAEncoder):\n",
        "    \"\"\"NEQR implementation.\"\"\"\n",
        "    def create_swap_test_circuit(self, seq1, seq2):\n",
        "        L = len(seq1)\n",
        "        n_pos = int(np.ceil(np.log2(L))) if L > 1 else 1\n",
        "        n_val = 2\n",
        "        def create_encoding_gate(sequence):\n",
        "            pos_reg_inner = QuantumRegister(n_pos)\n",
        "            val_reg_inner = QuantumRegister(n_val)\n",
        "            qc_enc = QuantumCircuit(pos_reg_inner, val_reg_inner, name=f'NEQR_Enc')\n",
        "            qc_enc.h(pos_reg_inner)\n",
        "            for i, nucleotide in enumerate(sequence):\n",
        "                pos_bin = format(i, f'0{n_pos}b')\n",
        "                nuc_bin = self.nucleotide_to_binary(nucleotide)\n",
        "                for j, bit in enumerate(pos_bin):\n",
        "                    if bit == '0': qc_enc.x(pos_reg_inner[j])\n",
        "                for j, bit in enumerate(nuc_bin):\n",
        "                    if bit == '1': qc_enc.mcx(pos_reg_inner[:], val_reg_inner[j])\n",
        "                for j, bit in enumerate(pos_bin):\n",
        "                    if bit == '0': qc_enc.x(pos_reg_inner[j])\n",
        "            return qc_enc.to_gate()\n",
        "        n_qubits_per_seq = n_pos + n_val\n",
        "        ancilla = QuantumRegister(1, 'ancilla')\n",
        "        reg1 = QuantumRegister(n_qubits_per_seq, 'seq1')\n",
        "        reg2 = QuantumRegister(n_qubits_per_seq, 'seq2')\n",
        "        creg = ClassicalRegister(1, 'c')\n",
        "        qc = QuantumCircuit(ancilla, reg1, reg2, creg)\n",
        "        qc.h(ancilla[0])\n",
        "        qc.append(create_encoding_gate(seq1), reg1[:])\n",
        "        qc.append(create_encoding_gate(seq2), reg2[:])\n",
        "        for i in range(n_qubits_per_seq):\n",
        "            qc.cswap(ancilla[0], reg1[i], reg2[i])\n",
        "        qc.h(ancilla[0])\n",
        "        qc.measure(ancilla[0], creg[0])\n",
        "        return qc\n",
        "\n",
        "class FRQIEncoder(QuantumDNAEncoder):\n",
        "    \"\"\"FRQI implementation.\"\"\"\n",
        "    def create_comparison_circuit(self, seq1, seq2):\n",
        "        L = len(seq1)\n",
        "        n_idx = int(np.ceil(np.log2(L))) if L > 1 else 1\n",
        "        strip = QuantumRegister(1, 'strip')\n",
        "        idx = QuantumRegister(n_idx, 'idx')\n",
        "        dna = QuantumRegister(1, 'dna')\n",
        "        creg = ClassicalRegister(1, 'c')\n",
        "        qc = QuantumCircuit(strip, idx, dna, creg)\n",
        "        qc.h(strip[0])\n",
        "        qc.h(idx)\n",
        "        for i in range(L):\n",
        "            pos_bin = format(i, f'0{n_idx}b')\n",
        "            for j, bit in enumerate(pos_bin):\n",
        "                if bit == '0': qc.x(idx[j])\n",
        "            angle1 = self.nucleotide_to_angle(seq1[i])\n",
        "            angle2 = self.nucleotide_to_angle(seq2[i])\n",
        "            controls = [strip[0]] + list(idx[:])\n",
        "            qc.x(strip[0])\n",
        "            if angle1 != 0: qc.mcry(angle1, controls, dna[0])\n",
        "            qc.x(strip[0])\n",
        "            if angle2 != 0: qc.mcry(angle2, controls, dna[0])\n",
        "            for j, bit in enumerate(pos_bin):\n",
        "                if bit == '0': qc.x(idx[j])\n",
        "        qc.h(strip[0])\n",
        "        qc.measure(strip[0], creg[0])\n",
        "        return qc"
      ],
      "metadata": {
        "id": "2J1OMOvjMTQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 3: UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "class SequenceAnalyzer:\n",
        "    \"\"\"Utility class for sequence analysis.\"\"\"\n",
        "    @staticmethod\n",
        "    def calculate_hamming_similarity(seq1, seq2):\n",
        "        if len(seq1) != len(seq2): raise ValueError(\"Sequences must have equal length\")\n",
        "        return sum(c1 == c2 for c1, c2 in zip(seq1, seq2)) / len(seq1)\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random_sequence(length, gc_content=None):\n",
        "        if gc_content is None:\n",
        "            return ''.join(np.random.choice(['A', 'T', 'G', 'C'], length))\n",
        "        if not (0 <= gc_content <= 1):\n",
        "            raise ValueError(\"gc_content must be between 0 and 1.\")\n",
        "        gc_count = int(length * gc_content)\n",
        "        at_count = length - gc_count\n",
        "        sequence = ['G'] * (gc_count // 2) + ['C'] * (gc_count - gc_count // 2)\n",
        "        sequence.extend(['A'] * (at_count // 2) + ['T'] * (at_count - at_count // 2))\n",
        "        np.random.shuffle(sequence)\n",
        "        return ''.join(sequence)\n",
        "\n",
        "class SimulationRunner:\n",
        "    \"\"\"Class for running quantum simulations.\"\"\"\n",
        "    def __init__(self, shots=8192):\n",
        "        self.shots = shots\n",
        "        self.backend = AerSimulator()\n",
        "\n",
        "    def run_circuit(self, circuit, noise_model=None):\n",
        "        backend_to_run = AerSimulator(noise_model=noise_model) if noise_model else self.backend\n",
        "        transpiled = transpile(circuit, backend_to_run)\n",
        "        result = backend_to_run.run(transpiled, shots=self.shots).result()\n",
        "        return result.get_counts()\n",
        "\n",
        "    def calculate_similarity_from_counts(self, counts):\n",
        "        p0 = counts.get('0', 0) / self.shots\n",
        "        return p0 - (1 - p0)\n",
        "\n",
        "    def run_neqr_simulation(self, seq1, seq2, noise_model=None):\n",
        "        circuit = NEQREncoder().create_swap_test_circuit(seq1, seq2)\n",
        "        counts = self.run_circuit(circuit, noise_model)\n",
        "        return self.calculate_similarity_from_counts(counts)\n",
        "\n",
        "    def run_frqi_simulation(self, seq1, seq2, noise_model=None):\n",
        "        circuit = FRQIEncoder().create_comparison_circuit(seq1, seq2)\n",
        "        counts = self.run_circuit(circuit, noise_model)\n",
        "        return self.calculate_similarity_from_counts(counts)"
      ],
      "metadata": {
        "id": "G1fbZUHqMXZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 4: DIVERSITY ANALYSIS MODULE\n",
        "# ============================================================================\n",
        "\n",
        "class DiversityAnalysis:\n",
        "    \"\"\"Module for testing diverse sequence cases, including GC content extremes.\"\"\"\n",
        "    def __init__(self, runner):\n",
        "        self.runner = runner\n",
        "        self.results = None\n",
        "\n",
        "    def generate_test_cases(self, length=6):\n",
        "        return {\n",
        "            'Identical Mix': [('ATCGAT', 'ATCGAT', 'Identical Mix')],\n",
        "            'Max Difference': [('AAAAAA', 'GGGGGG', 'Max Diff')],\n",
        "            'Single Mismatch': [('ATCGAT', 'ATCGTT', '1 Mismatch')],\n",
        "            '0% vs 0% GC': [(SequenceAnalyzer.generate_random_sequence(length, 0.0), SequenceAnalyzer.generate_random_sequence(length, 0.0), '0% vs 0% GC')],\n",
        "            '100% vs 100% GC': [(SequenceAnalyzer.generate_random_sequence(length, 1.0), SequenceAnalyzer.generate_random_sequence(length, 1.0), '100% vs 100% GC')],\n",
        "            '0% vs 100% GC': [(SequenceAnalyzer.generate_random_sequence(length, 0.0), SequenceAnalyzer.generate_random_sequence(length, 1.0), '0% vs 100% GC')]\n",
        "        }\n",
        "\n",
        "    def analyze(self, n_trials=20):\n",
        "        print(\"\\n Running Enhanced Diversity Analysis...\")\n",
        "        test_cases = self.generate_test_cases()\n",
        "        results_data = []\n",
        "        for category, cases in test_cases.items():\n",
        "            for seq1, seq2, desc in tqdm(cases, desc=f\"Testing {category}\"):\n",
        "                hamming = SequenceAnalyzer.calculate_hamming_similarity(seq1, seq2)\n",
        "                neqr_scores = [self.runner.run_neqr_simulation(seq1, seq2) for _ in range(n_trials)]\n",
        "                frqi_scores = [self.runner.run_frqi_simulation(seq1, seq2) for _ in range(n_trials)]\n",
        "                results_data.append({\n",
        "                    'Description': desc, 'Hamming': hamming,\n",
        "                    'NEQR_Mean': np.mean(neqr_scores), 'NEQR_Std': np.std(neqr_scores),\n",
        "                    'FRQI_Mean': np.mean(frqi_scores), 'FRQI_Std': np.std(frqi_scores),\n",
        "                })\n",
        "        self.results = pd.DataFrame(results_data)\n",
        "        return self.results\n",
        "\n",
        "    def plot_results(self):\n",
        "        \"\"\"REFACTORED: Creates a proper grouped bar chart.\"\"\"\n",
        "        if self.results is None: raise ValueError(\"Run analysis first\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(14, 8))\n",
        "        x = np.arange(len(self.results))\n",
        "        width = 0.25\n",
        "\n",
        "        # Plot bars for each method\n",
        "        ax.bar(x - width, self.results['NEQR_Mean'], width, yerr=self.results['NEQR_Std'],\n",
        "               label='NEQR', color=HOUSE_STYLE_COLORS['NEQR'], capsize=5, zorder=3)\n",
        "        ax.bar(x, self.results['FRQI_Mean'], width, yerr=self.results['FRQI_Std'],\n",
        "               label='FRQI', color=HOUSE_STYLE_COLORS['FRQI'], capsize=5, zorder=3)\n",
        "        ax.bar(x + width, self.results['Hamming'], width,\n",
        "               label='Classical Hamming', color=HOUSE_STYLE_COLORS['Classical Hamming'], zorder=3)\n",
        "\n",
        "        ax.set_ylabel('Similarity Score')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(self.results['Description'], rotation=45, ha='right')\n",
        "        ax.legend()\n",
        "        ax.set_ylim(bottom=0)\n",
        "\n",
        "        # Apply the consistent house style\n",
        "        apply_house_style(ax, title='Quantum vs. Classical Similarity for Diverse Cases')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/figures/diversity_comparison_grouped_bar.pdf')\n",
        "        plt.show()\n",
        "\n",
        "        self.results.to_csv('results/tables/diversity_results.csv', index=False)\n",
        "        print(\" Diversity analysis complete.\")\n"
      ],
      "metadata": {
        "id": "WAArarcgMeSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 5: STATISTICAL ANALYSIS MODULE\n",
        "# ============================================================================\n",
        "\n",
        "class StatisticalAnalysis:\n",
        "    \"\"\"Module for statistical testing across different GC contents.\"\"\"\n",
        "    def __init__(self, runner):\n",
        "        self.runner = runner\n",
        "        self.results = None\n",
        "\n",
        "    def analyze(self, n_sequences=15, sequence_length=6, gc_levels=[0.2, 0.5, 0.8]):\n",
        "        print(\"\\n Running Statistical Analysis across GC content...\")\n",
        "        results_data = []\n",
        "        for gc in tqdm(gc_levels, desc=\"Testing GC content levels\"):\n",
        "            for _ in range(n_sequences):\n",
        "                seq1 = SequenceAnalyzer.generate_random_sequence(sequence_length, gc_content=gc)\n",
        "                seq2 = SequenceAnalyzer.generate_random_sequence(sequence_length, gc_content=gc)\n",
        "                hamming = SequenceAnalyzer.calculate_hamming_similarity(seq1, seq2)\n",
        "                neqr_sim = self.runner.run_neqr_simulation(seq1, seq2)\n",
        "                frqi_sim = self.runner.run_frqi_simulation(seq1, seq2)\n",
        "                results_data.append({\n",
        "                    'gc_content': gc, 'hamming': hamming,\n",
        "                    'neqr_sim': neqr_sim, 'frqi_sim': frqi_sim,\n",
        "                    'neqr_error': abs(neqr_sim - hamming),\n",
        "                    'frqi_error': abs(frqi_sim - hamming)\n",
        "                })\n",
        "        self.results = pd.DataFrame(results_data)\n",
        "        return self.results\n",
        "\n",
        "    def plot_correlation(self):\n",
        "        \"\"\"REFACTORED: Plot 1 - Correlation scatter plot.\"\"\"\n",
        "        if self.results is None: raise ValueError(\"Run analysis first\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "        # Melt data for cleaner plotting with Seaborn\n",
        "        df_melt = self.results.melt(\n",
        "            id_vars=['hamming', 'gc_content'],\n",
        "            value_vars=['neqr_sim', 'frqi_sim'],\n",
        "            var_name='Method',\n",
        "            value_name='Quantum Similarity'\n",
        "        )\n",
        "        df_melt['Method'] = df_melt['Method'].str.replace('_sim', '').str.upper()\n",
        "\n",
        "        sns.scatterplot(data=df_melt, x='hamming', y='Quantum Similarity',\n",
        "                        hue='gc_content', style='Method', palette=VIRIDIS_PALETTE,\n",
        "                        ax=ax, s=100, alpha=0.8)\n",
        "\n",
        "        ax.plot([0, 1], [0, 1], 'r--', label='Perfect Agreement', zorder=1)\n",
        "        ax.set_xlabel('Classical Hamming Similarity')\n",
        "        ax.set_ylabel('Quantum Similarity')\n",
        "        ax.set_aspect('equal', 'box')\n",
        "        ax.legend(title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "        apply_house_style(ax, title='Correlation of Quantum vs. Classical Similarity')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/figures/statistical_correlation.pdf', bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_error_distribution(self):\n",
        "        \"\"\"REFACTORED: Plot 2 - Error distribution box plot.\"\"\"\n",
        "        if self.results is None: raise ValueError(\"Run analysis first\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 7))\n",
        "\n",
        "        df_melt = self.results.melt(id_vars=['gc_content'], value_vars=['neqr_error', 'frqi_error'],\n",
        "                                    var_name='Method', value_name='Absolute Error')\n",
        "        df_melt['Method'] = df_melt['Method'].str.replace('_error', '').str.upper()\n",
        "\n",
        "        sns.boxplot(data=df_melt, x='gc_content', y='Absolute Error', hue='Method',\n",
        "                    ax=ax, palette=HOUSE_STYLE_COLORS)\n",
        "\n",
        "        ax.set_xlabel('GC Content Level')\n",
        "        ax.set_ylabel('Absolute Error')\n",
        "\n",
        "        apply_house_style(ax, title='Absolute Error Distribution by GC Content')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/figures/statistical_error_boxplot.pdf')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "S9i_uQtIMteh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 6: NOISE ANALYSIS MODULE\n",
        "# ============================================================================\n",
        "\n",
        "class NoiseAnalysis:\n",
        "    \"\"\"Module for noise resilience testing across different GC contents.\"\"\"\n",
        "    def __init__(self, runner):\n",
        "        self.runner = runner\n",
        "        self.results = None\n",
        "\n",
        "    def create_noise_model(self, rate):\n",
        "        noise = NoiseModel()\n",
        "        error_1q = depolarizing_error(rate, 1)\n",
        "        error_2q = depolarizing_error(rate * 10, 2)\n",
        "        noise.add_all_qubit_quantum_error(error_1q, ['h', 'x', 'ry'])\n",
        "        noise.add_all_qubit_quantum_error(error_2q, ['cx', 'swap', 'mcx', 'mcry'])\n",
        "        return noise\n",
        "\n",
        "    def analyze(self, noise_levels=[0, 0.001, 0.005], n_sequences=5, sequence_length=4, gc_levels=[0.2, 0.5, 0.8]):\n",
        "        print(\"\\n Running Noise Analysis across GC content...\")\n",
        "        results_data = []\n",
        "        pbar = tqdm(total=len(noise_levels) * len(gc_levels) * n_sequences, desc=\"Noise Analysis\")\n",
        "        for noise_rate in noise_levels:\n",
        "            noise_model = self.create_noise_model(noise_rate) if noise_rate > 0 else None\n",
        "            for gc in gc_levels:\n",
        "                for _ in range(n_sequences):\n",
        "                    seq1 = SequenceAnalyzer.generate_random_sequence(sequence_length, gc)\n",
        "                    seq2 = SequenceAnalyzer.generate_random_sequence(sequence_length, gc)\n",
        "                    hamming = SequenceAnalyzer.calculate_hamming_similarity(seq1, seq2)\n",
        "                    neqr_sim = self.runner.run_neqr_simulation(seq1, seq2, noise_model)\n",
        "                    frqi_sim = self.runner.run_frqi_simulation(seq1, seq2, noise_model)\n",
        "                    results_data.append({'noise': noise_rate, 'gc_content': gc, 'method': 'NEQR', 'error': abs(neqr_sim - hamming)})\n",
        "                    results_data.append({'noise': noise_rate, 'gc_content': gc, 'method': 'FRQI', 'error': abs(frqi_sim - hamming)})\n",
        "                    pbar.update(1)\n",
        "        pbar.close()\n",
        "        self.results = pd.DataFrame(results_data)\n",
        "        return self.results\n",
        "\n",
        "    def _plot_single_method_noise(self, method_name, ax):\n",
        "        \"\"\"Internal helper to plot noise for one method.\"\"\"\n",
        "        df_method = self.results[self.results['method'] == method_name]\n",
        "\n",
        "        sns.lineplot(data=df_method, x='noise', y='error', hue='gc_content',\n",
        "                     palette=VIRIDIS_PALETTE, marker='o', ax=ax, errorbar='sd', zorder=3)\n",
        "\n",
        "        ax.set_xlabel(\"Depolarizing Error Rate\")\n",
        "        ax.set_ylabel(\"Mean Absolute Error\")\n",
        "        ax.set_xscale('symlog', linthresh=1e-4)\n",
        "        ax.set_yscale('log')\n",
        "        ax.legend(title='GC Content')\n",
        "\n",
        "        apply_house_style(ax, title=f\"Noise Resilience: {method_name}\")\n",
        "\n",
        "    def plot_noise_resilience(self):\n",
        "        \"\"\"REFACTORED: Creates separate plots for NEQR and FRQI noise resilience.\"\"\"\n",
        "        if self.results is None: raise ValueError(\"Run analysis first\")\n",
        "\n",
        "        # Plot for NEQR\n",
        "        fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
        "        self._plot_single_method_noise('NEQR', ax1)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/figures/noise_resilience_neqr.pdf')\n",
        "        plt.show()\n",
        "\n",
        "        # Plot for FRQI\n",
        "        fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
        "        self._plot_single_method_noise('FRQI', ax2)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/figures/noise_resilience_frqi.pdf')\n",
        "        plt.show()\n",
        "\n",
        "        self.results.to_csv('results/tables/noise_results_gc.csv', index=False)\n",
        "        print(\" Noise analysis complete.\")\n"
      ],
      "metadata": {
        "id": "NdW_mDtsM28P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 7: REPORT PREPRATION MODULE\n",
        "# ============================================================================\n",
        "\n",
        "class ComprehensiveReport:\n",
        "    \"\"\"Module for generating a final summary report.\"\"\"\n",
        "    def generate_summary_table(self, stat_df, noise_df):\n",
        "        summary = {}\n",
        "        summary['Avg Error (All GC)'] = {\n",
        "            'NEQR': stat_df['neqr_error'].mean(),\n",
        "            'FRQI': stat_df['frqi_error'].mean()\n",
        "        }\n",
        "        neqr_worst_gc = stat_df.groupby('gc_content')['neqr_error'].mean().max()\n",
        "        frqi_worst_gc = stat_df.groupby('gc_content')['frqi_error'].mean().max()\n",
        "        summary['Worst-Case Error (by GC)'] = {'NEQR': neqr_worst_gc, 'FRQI': frqi_worst_gc}\n",
        "        noise_level = noise_df['noise'].max()\n",
        "        noise_at_max = noise_df[noise_df['noise'] == noise_level]\n",
        "        summary[f'Error @ {noise_level:.3f} Noise'] = {\n",
        "            'NEQR': noise_at_max[noise_at_max['method'] == 'NEQR']['error'].mean(),\n",
        "            'FRQI': noise_at_max[noise_at_max['method'] == 'FRQI']['error'].mean()\n",
        "        }\n",
        "        summary_df = pd.DataFrame.from_dict(summary, orient='index')\n",
        "        summary_df['NEQR_is_Better'] = summary_df['NEQR'] < summary_df['FRQI']\n",
        "        return summary_df\n",
        "\n",
        "    def create_final_report(self, all_results):\n",
        "        \"\"\"REFACTORED: Applies house style to the summary bar chart.\"\"\"\n",
        "        print(\"\\n Generating Comprehensive Report...\")\n",
        "        summary_table = self.generate_summary_table(all_results['statistical'], all_results['noise'])\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        summary_table[['NEQR', 'FRQI']].plot(\n",
        "            kind='bar',\n",
        "            ax=ax,\n",
        "            rot=0,\n",
        "            color=[HOUSE_STYLE_COLORS['NEQR'], HOUSE_STYLE_COLORS['FRQI']],\n",
        "            zorder=3\n",
        "        )\n",
        "        ax.set_ylabel('Error Value (Lower is Better)')\n",
        "        ax.set_xlabel('')\n",
        "\n",
        "        apply_house_style(ax, title='Overall Performance Comparison')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('results/figures/overall_comparison_summary.pdf')\n",
        "        plt.show()\n",
        "\n",
        "        summary_table.to_csv('results/tables/summary_table.csv')\n",
        "        print(\" Comprehensive report generated!\")\n",
        "        print(\"\\n Summary of Results:\")\n",
        "        print(summary_table.round(4).to_string())\n",
        "        return summary_table"
      ],
      "metadata": {
        "id": "pr8_Fgi2NAQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWxAazxmQEMf"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 8: MAIN EXECUTION (Updated to call refactored plot functions)\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function to run all enhanced analyses.\"\"\"\n",
        "    print(\"\\n Starting Comprehensive Quantum DNA Sequence Analysis\")\n",
        "    all_results = {}\n",
        "    runner = SimulationRunner(shots=8192)\n",
        "\n",
        "    GC_LEVELS = [0.2, 0.5, 0.8]\n",
        "\n",
        "    # 1. Diversity Analysis\n",
        "    try:\n",
        "        diversity_analyzer = DiversityAnalysis(runner)\n",
        "        all_results['diversity'] = diversity_analyzer.analyze(n_trials=10)\n",
        "        diversity_analyzer.plot_results() # This now creates the improved plot\n",
        "        with open('results/checkpoints/checkpoint_diversity.pkl', 'wb') as f: pickle.dump(all_results['diversity'], f)\n",
        "        gc.collect()\n",
        "    except Exception as e: print(f\"Diversity Analysis failed: {e}\")\n",
        "\n",
        "    # 2. Statistical Analysis with GC Content\n",
        "    try:\n",
        "        stat_analyzer = StatisticalAnalysis(runner)\n",
        "        all_results['statistical'] = stat_analyzer.analyze(n_sequences=10, sequence_length=6, gc_levels=GC_LEVELS)\n",
        "        stat_analyzer.plot_correlation()        # CALL SEPARATE PLOT 1\n",
        "        stat_analyzer.plot_error_distribution() # CALL SEPARATE PLOT 2\n",
        "        with open('results/checkpoints/checkpoint_statistical.pkl', 'wb') as f: pickle.dump(all_results['statistical'], f)\n",
        "        gc.collect()\n",
        "    except Exception as e: print(f\"Statistical Analysis failed: {e}\")\n",
        "\n",
        "    # 3. Noise Analysis with GC Content\n",
        "    try:\n",
        "        noise_analyzer = NoiseAnalysis(runner)\n",
        "        all_results['noise'] = noise_analyzer.analyze(noise_levels=[0, 0.0009, 0.002], n_sequences=5, sequence_length=4, gc_levels=GC_LEVELS)\n",
        "        noise_analyzer.plot_noise_resilience()\n",
        "        with open('results/checkpoints/checkpoint_noise.pkl', 'wb') as f: pickle.dump(all_results['noise'], f)\n",
        "        gc.collect()\n",
        "    except Exception as e: print(f\"Noise Analysis failed: {e}\")\n",
        "\n",
        "    # 4. Generate Comprehensive Report\n",
        "    try:\n",
        "        if all(k in all_results for k in ['statistical', 'noise']):\n",
        "            report_generator = ComprehensiveReport()\n",
        "            report_generator.create_final_report(all_results)\n",
        "        else:\n",
        "            print(\"\\nSkipping final report due to failures in previous steps.\")\n",
        "    except Exception as e: print(f\"Report Generation failed: {e}\")\n",
        "\n",
        "    with open('results/all_results.pkl', 'wb') as f: pickle.dump(all_results, f)\n",
        "    print(\"\\n\" + \"=\"*70 + \"\\n ENHANCED ANALYSIS COMPLETE!\\n\" + \"=\"*70)\n",
        "    print(f\"Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "NhuJihImQJZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}